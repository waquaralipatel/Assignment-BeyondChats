# ğŸŸ¥ Phase 1 â€“ Backend (API + Scraper)

## ğŸ“Œ Overview

Phase 1 is the **core backend layer** of the BeyondChats assignment.  
It is responsible for scraping blog articles, storing them in MongoDB, and exposing REST APIs for other phases.

This phase acts as the **single source of truth** for the entire application.

---

## ğŸ§  Phase 1 Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BeyondChats Website â”‚
â”‚ (Blogs Pages) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Scraping
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Blog Scraper â”‚
â”‚ (Axios + Cheerio) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Store Data
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MongoDB Database â”‚
â”‚ (beyondchats) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ REST APIs
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Express Backend API â”‚
â”‚ (/api/articles) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

## ğŸ¯ Responsibilities

- Scrape BeyondChats blog articles
- Store articles in MongoDB
- Provide REST APIs for frontend & AI pipeline
- Manage database connection and persistence

---

## ğŸ›  Tech Stack

- Node.js
- Express.js
- MongoDB
- Mongoose
- Axios
- Cheerio

---

## ğŸ“ Folder Structure

backend/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ app.js # Application entry point
â”‚ â”œâ”€â”€ config/
â”‚ â”‚ â””â”€â”€ db.js # MongoDB connection
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â””â”€â”€ Article.js # Article schema
â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â””â”€â”€ articles.js # API routes
â”‚ â”œâ”€â”€ controllers/
â”‚ â”‚ â””â”€â”€ articleController.js
â”‚ â””â”€â”€ scraper/
â”‚ â””â”€â”€ scrapeOldBlogs.js # Blog scraping script
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json
â””â”€â”€ README.md


---

## âš™ï¸ Environment Setup

### Create the environment file
```bash
cp .env.example .env

## Update .env with the following values
PORT=5000
MONGO_URI=mongodb://127.0.0.1:27017/beyondchats

Execution Steps
1ï¸âƒ£ Install Dependencies
cd backend-laravel
npm install

2ï¸âƒ£ Start Backend Server
cd src
node app.js

âœ… Expected Output
ğŸš€ Server running on port 5000
âœ… MongoDB connected

3ï¸âƒ£ Run Blog Scraper (One-Time Setup)

The scraper fetches the oldest BeyondChats blog articles and stores them in MongoDB.

node scraper/scrapeOldBlogs.js

âœ… Expected Output
âœ… 5 oldest blogs scraped successfully

ğŸ”— API Endpoints
Method	Endpoint	Description
GET	/api/articles	Fetch all stored articles
GET	/api/articles/latest	Fetch the latest article
ğŸ§  Data Model (Article)

Each article stored in MongoDB contains:

title

slug

content

article_type (original / updated)

createdAt

updatedAt

ğŸ“ Notes & Considerations

Backend must be running before Phase 2 or Phase 3

Scraper converts relative URLs into absolute URLs

Database and collections are auto-created by MongoDB

APIs are designed to be consumed by multiple clients

Scraping is intended to be executed once during setup

âœ… Phase 1 Status

âœ” Backend server running
âœ” MongoDB connected
âœ” Articles scraped and stored
âœ” APIs exposed and tested
